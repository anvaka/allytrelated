# allytrelated

A crawler for related youtube channels. Why not? Just playing with the data,
maybe nothing major.

It works by performing BFS on youtube channels starting from [TotalBiscuit channel](https://www.youtube.com/user/TotalHalibut).
This will cover ~3 million channels.

Note: there is a bug in the current implementation which causes a memory leak
in OSX/Unix machines. Start the crawler under [forever](https://github.com/foreverjs/forever)
module. It will crawl enough pages before it fails and then it restarts.

# data format

Once crawling is done the final file is written into `youtube-user.json`, which
will take ~700MB on the hard drive. Each record has the following format:

``` json
{
  "id": "UCy1Ms_5qBTawC-k7PVjHXKQ",
  "title": "TotalBiscuit, The Cynical Brit",
  "related": [
    "UC3kJdy9_bXFg8flaSY3RAcQ",
    "UCSvQyDawUyfXzrSq4dTVraQ",
    "UCvk51_ZhXooIukEKlbw08rA",
    "UCqZ0rqkoUeYlcxlUyqSgpdg",
    "UCCbfB3cQtkEAiKfdRQnfQvw",
    "UC_ufxdQbKBrrMOiZ4LzrUyA",
    "UC90ThxjTNaHaqyPVtfyZ4hw",
    "UCWCw2Sd7RlYJ2yuNVHDWNOA",
    "UCS2OAdHoLt-9T6cG9A2H49Q"
  ],
  "subscribers": "2,104,917",
  "relatedTitle": "Check out our colleagues"
}
```

Note: YouTube has couple `related` sections. By default this crawler will take
only the first one (most of the time the first section is generated by users).

Once crawling is done, you can compact the graph by running:

```
node --max-old-space-size=10000 toBinaryGraph.js
```

This will store graph into `data` folder using [ngraph.tbinary](https://github.com/anvaka/ngraph.tobinary),
which compcats the data set 6.6x times (from `737MB` down to `112MB`)

# notes

I'm currently experimenting with clustered graph layout, and this repository
consist of crawler + clustering utilities. Ideally it all should be split up
into multiple repositories, but I'm not sure which experiment will survive and
which one will go away. So keeping it here.

## notes for future self

To generate clusters run:

```
# First index the youtube reachable graph (will take several weeks for single host)
node index.js

# store graph into binary format (fast)
node --max-old-space-size=10000 toBinaryGraph.js

# Detect all outgoing clusters using ngraph.cw (~60 minutes?).
# Outgoing cluster means that graph is considered directed, and only outgoing
# traversal from tail to head is allowed). This will save clusters into data/allClusters.json
node --max-old-space-size=10000 findClusters.js`

# If you wish to have graph of clusters (i.e. graph where each node is a
# cluster, and link between clsuters means there are connections in the original
# graph between nodes within cluster)
node --max-old-space-size=10000 saveClusterGraph.js`

# to visually debug individual cluster:
cd tools/cluster-view
npm i
npm start
open src/index.html

# you can add channel id to the query string to build cluster view for a channel
index.html?id=UCy1Ms_5qBTawC-k7PVjHXKQ
```

# license

MIT
